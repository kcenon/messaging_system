#pragma once

/*****************************************************************************
BSD 3-Clause License

Copyright (c) 2025, ğŸ€â˜€ğŸŒ•ğŸŒ¥ ğŸŒŠ
All rights reserved.
*****************************************************************************/

#include "../interfaces/multi_process_monitoring_interface.h"
#include "optimized_storage.h"
#include <memory>
#include <functional>
#include <chrono>
#include <thread>
#include <deque>

namespace monitoring_module {

/**
 * @class performance_optimizer
 * @brief ì„±ëŠ¥ ìµœì í™” ê´€ë¦¬ì
 * 
 * ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ìë™ìœ¼ë¡œ ìµœì í™”
 */
class performance_optimizer {
public:
    /**
     * @struct optimization_config
     * @brief ìµœì í™” ì„¤ì •
     */
    struct optimization_config {
        bool enable_compression{true};          // ë°ì´í„° ì••ì¶• í™œì„±í™”
        bool enable_batching{true};             // ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”
        bool enable_tiered_storage{true};       // ê³„ì¸µí˜• ì €ì¥ì†Œ í™œì„±í™”
        bool enable_adaptive_sampling{true};    // ì ì‘í˜• ìƒ˜í”Œë§ í™œì„±í™”
        std::size_t batch_size{100};            // ë°°ì¹˜ í¬ê¸°
        std::size_t compression_threshold{1000}; // ì••ì¶• ì„ê³„ê°’
        std::chrono::milliseconds batch_interval{100}; // ë°°ì¹˜ ê°„ê²©
    };
    
    /**
     * @struct optimization_stats
     * @brief ìµœì í™” í†µê³„
     */
    struct optimization_stats {
        std::size_t memory_saved_bytes{0};      // ì ˆì•½ëœ ë©”ëª¨ë¦¬
        std::size_t cpu_cycles_saved{0};        // ì ˆì•½ëœ CPU ì‚¬ì´í´
        double compression_ratio{1.0};          // ì••ì¶•ë¥ 
        std::size_t batches_processed{0};       // ì²˜ë¦¬ëœ ë°°ì¹˜ ìˆ˜
        std::size_t samples_skipped{0};         // ê±´ë„ˆë›´ ìƒ˜í”Œ ìˆ˜
        std::chrono::nanoseconds time_saved_ns{0}; // ì ˆì•½ëœ ì‹œê°„
    };
    
    /**
     * @brief ìƒì„±ì
     * @param config ìµœì í™” ì„¤ì •
     */
    explicit performance_optimizer(const optimization_config& config);
    
    /**
     * @brief ë©”íŠ¸ë¦­ ìµœì í™” ì²˜ë¦¬
     * @param snapshot ì›ë³¸ ë©”íŠ¸ë¦­
     * @return ìµœì í™” ì—¬ë¶€
     */
    bool optimize_metric(const monitoring_interface::metrics_snapshot& snapshot);
    
    /**
     * @brief ì ì‘í˜• ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì¡°ì •
     * @param process_id í”„ë¡œì„¸ìŠ¤ ID
     * @param current_load í˜„ì¬ ë¶€í•˜
     */
    void adjust_sampling_rate(const monitoring_interface::process_identifier& process_id,
                            double current_load);
    
    /**
     * @brief ë©”ëª¨ë¦¬ ì••ë ¥ì— ë”°ë¥¸ ìë™ ì¡°ì •
     * @param memory_pressure ë©”ëª¨ë¦¬ ì••ë ¥ (0-1)
     */
    void adapt_to_memory_pressure(double memory_pressure);
    
    /**
     * @brief CPU ë¶€í•˜ì— ë”°ë¥¸ ìë™ ì¡°ì •
     * @param cpu_load CPU ë¶€í•˜ (0-100)
     */
    void adapt_to_cpu_load(double cpu_load);
    
    /**
     * @brief ìµœì í™” í†µê³„ ì¡°íšŒ
     * @return ìµœì í™” í†µê³„
     */
    optimization_stats get_stats() const;
    
    /**
     * @brief ìµœì í™”ëœ ì €ì¥ì†Œ ì ‘ê·¼
     * @return ê³„ì¸µí˜• ì €ì¥ì†Œ
     */
    tiered_storage& get_storage() { return *storage_; }
    
    /**
     * @brief ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì½œë°± ì„¤ì •
     * @param callback ë°°ì¹˜ ì²˜ë¦¬ ì½œë°±
     */
    void set_batch_callback(batch_metrics_processor::batch_callback callback);
    
private:
    optimization_config config_;
    mutable std::mutex stats_mutex_;
    optimization_stats stats_;
    
    // ìµœì í™” ì»´í¬ë„ŒíŠ¸
    std::unique_ptr<tiered_storage> storage_;
    std::unique_ptr<batch_metrics_processor> batch_processor_;
    std::unique_ptr<compressed_metrics_storage> compression_buffer_;
    
    // ì ì‘í˜• ìƒ˜í”Œë§
    struct sampling_state {
        double rate{1.0};  // ìƒ˜í”Œë§ ë¹„ìœ¨ (0-1)
        std::chrono::steady_clock::time_point last_sample;
        std::size_t skip_count{0};
    };
    std::unordered_map<monitoring_interface::process_identifier, sampling_state> sampling_states_;
    std::mutex sampling_mutex_;
    
    // ë‚´ë¶€ í—¬í¼
    bool should_sample(const monitoring_interface::process_identifier& process_id);
    void update_stats(std::size_t memory_saved, std::size_t cpu_saved);
};

/**
 * @class auto_scaler
 * @brief ìë™ ìŠ¤ì¼€ì¼ëŸ¬
 * 
 * ë¶€í•˜ì— ë”°ë¼ ëª¨ë‹ˆí„°ë§ ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì •
 */
class auto_scaler {
public:
    /**
     * @struct scaling_policy
     * @brief ìŠ¤ì¼€ì¼ë§ ì •ì±…
     */
    struct scaling_policy {
        double cpu_threshold_up{80.0};      // ìŠ¤ì¼€ì¼ ì—… CPU ì„ê³„ê°’
        double cpu_threshold_down{30.0};    // ìŠ¤ì¼€ì¼ ë‹¤ìš´ CPU ì„ê³„ê°’
        double memory_threshold_up{80.0};   // ìŠ¤ì¼€ì¼ ì—… ë©”ëª¨ë¦¬ ì„ê³„ê°’
        double memory_threshold_down{30.0}; // ìŠ¤ì¼€ì¼ ë‹¤ìš´ ë©”ëª¨ë¦¬ ì„ê³„ê°’
        std::chrono::seconds cooldown{60};  // ì¿¨ë‹¤ìš´ ê¸°ê°„
        double scale_factor{1.5};           // ìŠ¤ì¼€ì¼ íŒ©í„°
    };
    
    /**
     * @struct scaling_decision
     * @brief ìŠ¤ì¼€ì¼ë§ ê²°ì •
     */
    struct scaling_decision {
        enum class action { none, scale_up, scale_down };
        action recommended_action{action::none};
        double confidence{0.0};             // ê²°ì • ì‹ ë¢°ë„ (0-1)
        std::string reason;                 // ê²°ì • ì´ìœ 
        std::size_t recommended_resources{0}; // ê¶Œì¥ ë¦¬ì†ŒìŠ¤
    };
    
    /**
     * @brief ìƒì„±ì
     * @param policy ìŠ¤ì¼€ì¼ë§ ì •ì±…
     */
    explicit auto_scaler(const scaling_policy& policy);
    
    /**
     * @brief ìŠ¤ì¼€ì¼ë§ ê²°ì •
     * @param current_metrics í˜„ì¬ ë©”íŠ¸ë¦­
     * @return ìŠ¤ì¼€ì¼ë§ ê²°ì •
     */
    scaling_decision decide(const monitoring_interface::metrics_snapshot& current_metrics);
    
    /**
     * @brief ì˜ˆì¸¡ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ ê²°ì •
     * @param predicted_load ì˜ˆì¸¡ëœ ë¶€í•˜
     * @param time_horizon ì˜ˆì¸¡ ì‹œê°„
     * @return ìŠ¤ì¼€ì¼ë§ ê²°ì •
     */
    scaling_decision decide_predictive(double predicted_load,
                                     std::chrono::seconds time_horizon);
    
    /**
     * @brief ìŠ¤ì¼€ì¼ë§ ì´ë ¥ ì¡°íšŒ
     * @param count ì¡°íšŒí•  ê°œìˆ˜
     * @return ìŠ¤ì¼€ì¼ë§ ê²°ì • ì´ë ¥
     */
    std::vector<std::pair<std::chrono::steady_clock::time_point, scaling_decision>>
    get_history(std::size_t count = 10) const;
    
private:
    scaling_policy policy_;
    std::chrono::steady_clock::time_point last_scale_time_;
    
    struct resource_state {
        std::size_t current_resources{1};
        double smoothed_cpu_load{0.0};
        double smoothed_memory_load{0.0};
    };
    resource_state state_;
    
    mutable std::mutex history_mutex_;
    std::deque<std::pair<std::chrono::steady_clock::time_point, scaling_decision>> history_;
    
    bool is_in_cooldown() const;
    void update_smoothed_metrics(double cpu_load, double memory_load);
    void record_decision(const scaling_decision& decision);
};

/**
 * @class distributed_aggregator
 * @brief ë¶„ì‚° ì§‘ê³„ê¸°
 * 
 * ì—¬ëŸ¬ ëª¨ë‹ˆí„°ë§ ì¸ìŠ¤í„´ìŠ¤ì˜ ë©”íŠ¸ë¦­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì§‘ê³„
 */
class distributed_aggregator {
public:
    using aggregation_callback = std::function<void(
        const monitoring_interface::multi_process_metrics_snapshot&)>;
    
    /**
     * @struct aggregation_config
     * @brief ì§‘ê³„ ì„¤ì •
     */
    struct aggregation_config {
        std::chrono::milliseconds aggregation_interval{1000};
        bool enable_parallel_aggregation{true};
        std::size_t worker_threads{4};
        bool enable_incremental_aggregation{true};
    };
    
    /**
     * @brief ìƒì„±ì
     * @param config ì§‘ê³„ ì„¤ì •
     */
    explicit distributed_aggregator(const aggregation_config& config);
    
    /**
     * @brief ë¡œì»¬ ë©”íŠ¸ë¦­ ì¶”ê°€
     * @param node_id ë…¸ë“œ ID
     * @param snapshot ë©”íŠ¸ë¦­ ìŠ¤ëƒ…ìƒ·
     */
    void add_local_metrics(const std::string& node_id,
                          const monitoring_interface::multi_process_metrics_snapshot& snapshot);
    
    /**
     * @brief ê¸€ë¡œë²Œ ì§‘ê³„ ìˆ˜í–‰
     * @return ì§‘ê³„ëœ ë©”íŠ¸ë¦­
     */
    monitoring_interface::multi_process_metrics_snapshot aggregate_global();
    
    /**
     * @brief ì§‘ê³„ ì½œë°± ì„¤ì •
     * @param callback ì§‘ê³„ ì™„ë£Œ ì½œë°±
     */
    void set_aggregation_callback(aggregation_callback callback);
    
    /**
     * @brief ë…¸ë“œ ìƒíƒœ ì¡°íšŒ
     * @return ë…¸ë“œë³„ ìƒíƒœ ë§µ
     */
    std::unordered_map<std::string, std::chrono::steady_clock::time_point>
    get_node_status() const;
    
private:
    aggregation_config config_;
    aggregation_callback callback_;
    
    struct node_data {
        monitoring_interface::multi_process_metrics_snapshot latest_snapshot;
        std::chrono::steady_clock::time_point last_update;
        bool is_active{true};
    };
    
    mutable std::shared_mutex data_mutex_;
    std::unordered_map<std::string, node_data> node_metrics_;
    
    std::atomic<bool> aggregating_{false};
    std::thread aggregation_thread_;
    
    void parallel_aggregate(monitoring_interface::multi_process_metrics_snapshot& result);
    void incremental_aggregate(const std::string& node_id,
                             const monitoring_interface::multi_process_metrics_snapshot& snapshot,
                             monitoring_interface::multi_process_metrics_snapshot& result);
};

} // namespace monitoring_module